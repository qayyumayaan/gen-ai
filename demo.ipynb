{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translator demo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "response = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French: I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joke generator demo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club name generator demo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def generate_club_name(club_type):\n",
    "    llm = OpenAI(temperature = 0.7)\n",
    "    \n",
    "    prompt_template_name = PromptTemplate(\n",
    "        input_variables=['club_type'],\n",
    "        template = \"Suggest five cool names for a new {club_type} club. \"\n",
    "    )\n",
    "    name_chain = LLMChain(llm=llm, prompt = prompt_template_name)\n",
    "    \n",
    "    response = name_chain({'club_type' : club_type})\n",
    "    return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(generate_club_name(\"Computer Engineering\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a demonstration on using vector stores with LanceDB to find text similarities. \n",
    "https://python.langchain.com/docs/get_started/quickstart\n",
    "https://python.langchain.com/docs/modules/data_connection/vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import LanceDB\n",
    "\n",
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"/tmp/lancedb\")\n",
    "table = db.create_table(\n",
    "    \"my_table\",\n",
    "    data=[\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
    "            \"text\": \"Hello World\",\n",
    "            \"id\": \"1\",\n",
    "        }\n",
    "    ],\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('art_of_war.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = LanceDB.from_documents(documents, OpenAIEmbeddings(), connection=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17. Thus we may know that there are five essentials for victory: (1)\n",
      "He will win who knows when to fight and when not to fight. (2) He\n",
      "will win who knows how to handle both superior and inferior forces.\n",
      "(3) He will win whose army is animated by the same spirit throughout\n",
      "all its ranks. (4) He will win who, prepared himself, waits to take\n",
      "the enemy unprepared. (5) He will win who has military capacity and\n",
      "is not interfered with by the sovereign. \n",
      "\n",
      "18. Hence the saying: If you know the enemy and know yourself, you\n",
      "need not fear the result of a hundred battles. If you know yourself\n",
      "but not the enemy, for every victory gained you will also suffer a\n",
      "defeat. If you know neither the enemy nor yourself, you will succumb\n",
      "in every battle. \n",
      "\n",
      "IV. Tactical Dispositions\n",
      "\n",
      "1. Sun Tzu said: The good fighters of old first put themselves beyond\n",
      "the possibility of defeat, and then waited for an opportunity of defeating\n",
      "the enemy.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did Sun Tzu say about understanding the enemy?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but does not give specific justification for its advice. To correct that, we can have ChatGPT receive the embedding text info and then have it come up with a reason for why the text is the most relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "19. If it is to your advantage, make a forward move; if not, stay\n",
      "where you are. \n",
      "\n",
      "20. Anger may in time change to gladness; vexation may be succeeded\n",
      "by content. \n",
      "\n",
      "21. But a kingdom that has once been destroyed can never come again\n",
      "into being; nor can the dead ever be brought back to life.\n",
      "\n",
      "22. Hence the enlightened ruler is heedful, and the good general full\n",
      "of caution. This is the way to keep a country at peace and an army\n",
      "intact. \n",
      "\n",
      "XIII. The Use of Spies\n",
      "\n",
      "1. Sun Tzu said: Raising a host of a hundred thousand men and marching\n",
      "them great distances entails heavy loss on the people and a drain\n",
      "on the resources of the State. The daily expenditure will amount to\n",
      "a thousand ounces of silver. There will be commotion at home and abroad,\n",
      "and men will drop down exhausted on the highways. As many as seven\n",
      "hundred thousand families will be impeded in their labor.\n",
      "Explanation: \n",
      "The excerpt from Sun Tzu's text is similar to the query \"Sun Tzu's advice on applying to college\" in that both involve strategic decision-making and the consideration of advantages and disadvantages. In the excerpt, Sun Tzu advises making a forward move if it is advantageous, and if not, staying put. Similarly, when applying to college, it is important to consider whether a particular action or decision will be advantageous or not. Sun Tzu's mention of anger changing to gladness and vexation to content also relates to the emotional journey of applying to college, where initial challenges and setbacks can eventually lead to positive outcomes and satisfaction. Finally, Sun Tzu's emphasis on being cautious and heedful can be applied to the college application process as well, highlighting the importance of being aware of potential risks and making informed decisions to ensure success.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "query = \"Sun Tzu's advice on applying to college?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(\"Text: \")\n",
    "print(docs[0].page_content)\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": f\"Explain how the following excerpt from Sun Tzu's text is similar to the query '{query}':\\n\\n{docs[0].page_content}\"}\n",
    "  ]\n",
    ")\n",
    "message_content = response.choices[0].message.content\n",
    "\n",
    "print(\"Explanation: \")\n",
    "print(message_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot has a technique of using embeddings to find the most relevant text passage from Sun Tzu's \"Art of War\" in response to a given situation, followed by an explanation of the similarity. It has several pros and cons:\n",
    "\n",
    "### Pros:\n",
    "1. **Contextual Relevance:** Embeddings capture the semantic context of words, enabling the bot to find passages that are contextually relevant to the query.\n",
    "2. **Efficiency:** This method can be computationally efficient, especially if embeddings are pre-computed.\n",
    "3. **Flexibility:** The approach can handle a variety of queries, including abstract or nuanced situations.\n",
    "4. **Explanation Component:** Providing a rationale for the chosen passage helps in making the bot's decision process transparent and understandable.\n",
    "\n",
    "### Cons:\n",
    "1. **Quality of Embeddings:** The effectiveness of this approach heavily depends on the quality of the embeddings. Poorly trained or unsuitable embeddings might yield irrelevant results.\n",
    "2. **Limited to Textual Similarity:** The bot focuses on textual similarity and might miss contextually deeper or metaphorical connections that a human expert could make.\n",
    "3. **Data Limitation:** It's confined to the content and wisdom of \"Art of War.\" Situations requiring knowledge outside this text won't be effectively addressed.\n",
    "4. **Over-reliance on Textual Data:** The approach may not account for the non-textual nuances of a situation (e.g., emotional, cultural aspects).\n",
    "\n",
    "### Alternatives:\n",
    "1. **Rule-Based Systems:** These use predefined rules for decision-making. While they're more transparent, they lack the flexibility and contextual understanding of embedding-based systems.\n",
    "2. **Machine Learning Classifiers:** Classifiers can categorize situations into predefined categories, which could be linked to specific advice. This approach might be less nuanced in understanding complex queries.\n",
    "3. **Human Expert Involvement:** Involving domain experts in the decision process can provide deeper insights but is less scalable and more time-consuming.\n",
    "\n",
    "In summary, the technique is efficient and contextually aware, but its effectiveness hinges on the quality of embeddings and the scope of the source text. It's well-suited for textual analysis but might not capture deeper, non-textual insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
